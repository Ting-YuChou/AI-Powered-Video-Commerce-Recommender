# AI-Powered Video Commerce Recommender - Docker Compose
# ========================================================
# Complete containerized deployment for the video commerce recommendation system

version: '3.8'

services:
  # Main Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
      args:
        - PYTHON_VERSION=3.10
        - BUILD_ENV=production
    container_name: video-commerce-app
    ports:
      - "8000:8000"
    environment:
      # Application Settings
      - ENVIRONMENT=production
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - API_WORKERS=2
      - API_DEBUG=false
      
      # Redis Connection
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      
      # Model Settings
      - MODEL_DEVICE=auto
      - MODEL_CACHE_DIR=/app/models
      - MODEL_ENABLE_GPU=true
      
      # Data Settings
      - DATA_UPLOAD_DIR=/app/uploads
      - DATA_LOAD_SAMPLE_DATA=true
      
      # Monitoring
      - MONITORING_LOG_LEVEL=INFO
      - MONITORING_ENABLE_METRICS=true
      
      # Kafka Settings
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_ENABLE=true
    volumes:
      # Persistent storage for models and data
      - models_data:/app/models
      - upload_data:/app/uploads
      - logs_data:/app/logs
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - video-commerce-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Redis - Feature Store and Caching
  redis:
    image: redis:7-alpine
    container_name: video-commerce-redis
    ports:
      - "6379:6379"
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
    networks:
      - video-commerce-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: video-commerce-prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - prometheus_data:/prometheus
    networks:
      - video-commerce-network
    restart: unless-stopped

  # Grafana - Metrics Visualization
  grafana:
    image: grafana/grafana:latest
    container_name: video-commerce-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - video-commerce-network
    restart: unless-stopped
    depends_on:
      - prometheus

  # Zookeeper - Kafka Coordination (required for Kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: video-commerce-zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - video-commerce-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Kafka - Message Streaming Platform
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: video-commerce-kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - video-commerce-network
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Kafka UI - Web interface for Kafka management (optional, for development)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: video-commerce-kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: video-commerce
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - video-commerce-network
    depends_on:
      - kafka
    restart: unless-stopped

  # Video Processing Worker - Consumes from Kafka
  video-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: video-commerce-worker
    command: python -m kafka_workers.video_processor
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - WORKER_TYPE=video_processor
    volumes:
      - models_data:/app/models
      - upload_data:/app/uploads
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - video-commerce-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Feature Update Worker - Consumes user interactions from Kafka
  feature-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: video-commerce-feature-worker
    command: python -m kafka_workers.feature_updater
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - WORKER_TYPE=feature_updater
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - video-commerce-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

# Named Volumes
volumes:
  models_data:
    driver: local
  upload_data:
    driver: local
  logs_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local

# Networks
networks:
  video-commerce-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# =============================================================================
# Usage Examples
# =============================================================================
#
# Start all services:
#   docker-compose up -d
#
# Start only the app:
#   docker-compose up app
#
# View logs:
#   docker-compose logs -f app
#
# Shell into container:
#   docker-compose exec app bash
#
# Stop all services:
#   docker-compose down
#
# Stop and remove volumes:
#   docker-compose down -v
#
# Scale the application:
#   docker-compose up --scale app=3
#
# Rebuild and start:
#   docker-compose up --build
#
# =============================================================================
# Service Endpoints
# =============================================================================
#
# Application API:       http://localhost:8000
# API Documentation:     http://localhost:8000/docs
# Health Check:          http://localhost:8000/health
# Kafka Health:          http://localhost:8000/kafka/health
# Kafka Topics:          http://localhost:8000/kafka/topics
# Redis:                 localhost:6379
# Kafka (internal):      kafka:9092
# Kafka (external):      localhost:29092
# Zookeeper:             localhost:2181
# Kafka UI:              http://localhost:8080
# Prometheus:            http://localhost:9090
# Grafana:               http://localhost:3000 (admin/admin)

