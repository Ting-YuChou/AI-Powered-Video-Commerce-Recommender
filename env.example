# AI Video Commerce Recommender - Environment Configuration
# =========================================================
# Copy this file to .env and update with your actual values
# DO NOT commit .env file to version control

# =============================================================================
# API Server Configuration
# =============================================================================
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false
API_RELOAD=false
API_WORKERS=1

# CORS settings (comma-separated origins)
API_CORS_ORIGINS=*
API_CORS_CREDENTIALS=true

# Request limits
API_MAX_REQUEST_SIZE=104857600  # 100MB
API_REQUEST_TIMEOUT=30
API_MAX_CONCURRENT_REQUESTS=100

# Security
API_API_KEY=  # Optional: Set for API authentication
API_RATE_LIMIT_REQUESTS=1000  # Requests per minute

# =============================================================================
# Redis Configuration
# =============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=  # Leave empty if no password
REDIS_DECODE_RESPONSES=true
REDIS_MAX_CONNECTIONS=100
REDIS_SOCKET_TIMEOUT=30
REDIS_SOCKET_CONNECT_TIMEOUT=30
REDIS_RETRY_ON_TIMEOUT=true

# =============================================================================
# Machine Learning Model Configuration
# =============================================================================
# CLIP model settings
MODEL_CLIP_MODEL=openai/clip-vit-large-patch14
MODEL_EMBEDDING_DIM=512

# Model paths (optional - leave empty for default)
MODEL_RANKING_MODEL_PATH=
MODEL_CF_MODEL_PATH=

# Processing settings
MODEL_CACHE_DIR=/tmp/models
MODEL_DEVICE=auto  # auto, cpu, or cuda
MODEL_BATCH_SIZE=32
MODEL_MAX_VIDEO_LENGTH=300  # seconds
MODEL_NUM_KEYFRAMES=8

# Performance settings
MODEL_ENABLE_QUANTIZATION=false
MODEL_ENABLE_GPU=true
MODEL_MAX_CONCURRENT_REQUESTS=10

# =============================================================================
# Vector Search Configuration
# =============================================================================
VECTOR_INDEX_PATH=/tmp/vector_index.faiss
VECTOR_EMBEDDING_DIM=512
VECTOR_INDEX_TYPE=HNSW  # HNSW or IVF

# HNSW parameters
VECTOR_HNSW_M=32
VECTOR_HNSW_EF_CONSTRUCTION=200
VECTOR_HNSW_EF_SEARCH=50

# Search parameters
VECTOR_SEARCH_K=100
VECTOR_SIMILARITY_THRESHOLD=0.1

# =============================================================================
# Recommendation Engine Configuration
# =============================================================================
# Collaborative filtering
RECOMMENDATION_CF_FACTORS=64
RECOMMENDATION_CF_REGULARIZATION=0.1
RECOMMENDATION_CF_ITERATIONS=50

# Candidate generation
RECOMMENDATION_CANDIDATES_PER_SOURCE=100
RECOMMENDATION_MAX_TOTAL_CANDIDATES=500

# Ranking weights (should sum to ~1.0)
RECOMMENDATION_CF_WEIGHT=0.4
RECOMMENDATION_CONTENT_WEIGHT=0.3
RECOMMENDATION_POPULARITY_WEIGHT=0.3

# Trending algorithm
RECOMMENDATION_TRENDING_DECAY_FACTOR=0.95
RECOMMENDATION_TRENDING_WINDOW_HOURS=24

# Diversity settings
RECOMMENDATION_ENABLE_DIVERSITY=true
RECOMMENDATION_DIVERSITY_FACTOR=0.1
RECOMMENDATION_MAX_ITEMS_PER_CATEGORY=3

# =============================================================================
# Ranking Model Configuration
# =============================================================================
RANKING_MODEL_TYPE=neural
RANKING_HIDDEN_DIMS=256,128,64  # Comma-separated values
RANKING_DROPOUT_RATE=0.2
RANKING_LEARNING_RATE=0.001

# Multi-objective optimization
RANKING_ENABLE_MULTI_OBJECTIVE=true
RANKING_CTR_WEIGHT=1.0
RANKING_CVR_WEIGHT=2.0
RANKING_GMV_WEIGHT=3.0

# Training settings
RANKING_EPOCHS=100
RANKING_BATCH_SIZE=1024
RANKING_EARLY_STOPPING_PATIENCE=10

# =============================================================================
# Cache Configuration
# =============================================================================
CACHE_ENABLE_CACHING=true
CACHE_DEFAULT_TTL=3600  # seconds

# Specific cache TTLs
CACHE_USER_FEATURES_TTL=1800
CACHE_CONTENT_FEATURES_TTL=86400
CACHE_RECOMMENDATIONS_TTL=900

# Cache size limits
CACHE_MAX_CACHE_SIZE=10000
CACHE_CLEANUP_INTERVAL=3600

# Intelligent caching
CACHE_ADAPTIVE_TTL=true
CACHE_HIGH_ACTIVITY_TTL=300
CACHE_LOW_ACTIVITY_TTL=7200

# =============================================================================
# Monitoring and Logging Configuration
# =============================================================================
MONITORING_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
MONITORING_LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Metrics collection
MONITORING_ENABLE_METRICS=true
MONITORING_METRICS_INTERVAL=60

# Health checks
MONITORING_HEALTH_CHECK_INTERVAL=30
MONITORING_COMPONENT_TIMEOUT=5

# Performance monitoring
MONITORING_SLOW_REQUEST_THRESHOLD=1.0  # seconds
MONITORING_ENABLE_REQUEST_LOGGING=true

# Alerting thresholds
MONITORING_ERROR_RATE_THRESHOLD=0.05  # 5%
MONITORING_RESPONSE_TIME_THRESHOLD=500  # milliseconds
MONITORING_MEMORY_THRESHOLD=0.8  # 80%

# =============================================================================
# Data Management Configuration
# =============================================================================
# Sample data
DATA_LOAD_SAMPLE_DATA=true
DATA_SAMPLE_DATA_PATH=data/sample_products.json
DATA_SAMPLE_USERS=1000
DATA_SAMPLE_INTERACTIONS=10000

# Data storage
DATA_UPLOAD_DIR=/tmp/uploads
DATA_MAX_FILE_SIZE=524288000  # 500MB in bytes
DATA_ALLOWED_EXTENSIONS=.mp4,.avi,.mov,.mkv

# Data processing
DATA_CLEANUP_TEMP_FILES=true
DATA_TEMP_FILE_TTL=3600

# =============================================================================
# Environment Settings
# =============================================================================
ENVIRONMENT=development  # development, production, or test
NO_SAMPLE_DATA=false  # Set to true to skip sample data loading

# =============================================================================
# Optional External Services
# =============================================================================
# Sentry (Error tracking)
# SENTRY_DSN=

# AWS S3 (File storage)
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_REGION=us-east-1
# AWS_S3_BUCKET=

# Database (if using instead of Redis)
# DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# =============================================================================
# GPU Configuration (Optional)
# =============================================================================
# CUDA settings
# CUDA_VISIBLE_DEVICES=0
# CUDA_DEVICE_ORDER=PCI_BUS_ID

# =============================================================================
# Production Settings
# =============================================================================
# Uncomment and configure for production deployment

# Security
# SECRET_KEY=your-secret-key-here
# JWT_SECRET_KEY=your-jwt-secret-here
# JWT_ALGORITHM=HS256
# JWT_EXPIRE_MINUTES=30

# HTTPS
# SSL_CERT_FILE=/path/to/cert.pem
# SSL_KEY_FILE=/path/to/key.pem

# Monitoring services
# PROMETHEUS_PORT=9090
# GRAFANA_PORT=3000

# Load balancing
# WORKER_CONNECTIONS=1000
# KEEPALIVE_TIMEOUT=65

# =============================================================================
# Notes
# =============================================================================
# 1. For production, set ENVIRONMENT=production and disable debug/reload
# 2. Always set strong passwords for Redis and databases
# 3. Use environment-specific .env files (.env.production, .env.development)
# 4. For GPU support, ensure CUDA drivers are installed and set MODEL_DEVICE=cuda
# 5. Adjust batch sizes and worker counts based on available resources
# 6. Monitor memory usage and adjust cache sizes accordingly
# 7. Enable metrics and logging for production environments
# 8. Use external secret management for sensitive values in production

